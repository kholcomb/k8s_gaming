✅ SOLUTION HINT

Complete Fix:
=============

Here's exactly what to add to broken.yaml:

**Find the Service:**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: session-service
  namespace: k8squest
spec:
  selector:
    app: session-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  # Nothing here - missing sessionAffinity!
```

**Add Session Affinity:**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: session-service
  namespace: k8squest
spec:
  selector:
    app: session-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  sessionAffinity: ClientIP           # ✅ ADD THIS
  sessionAffinityConfig:              # ✅ ADD THIS (optional but recommended)
    clientIP:
      timeoutSeconds: 10800           # ✅ ADD THIS (3 hours)
```

Step-by-Step:
-------------

1. **Edit broken.yaml:**
   Find the Service resource and add the sessionAffinity lines after the ports section.

2. **Apply the fix:**
   ```bash
   kubectl apply -f broken.yaml
   ```

   You should see:
   ```
   pod/session-app-1 unchanged
   pod/session-app-2 unchanged
   pod/session-app-3 unchanged
   service/session-service configured
   pod/client unchanged
   ```

3. **Verify the configuration:**
   ```bash
   kubectl get service session-service -n k8squest -o yaml
   ```

   Look for:
   ```yaml
   spec:
     sessionAffinity: ClientIP
     sessionAffinityConfig:
       clientIP:
         timeoutSeconds: 10800
   ```

4. **Watch the client logs:**
   ```bash
   kubectl logs client -n k8squest --tail=20
   ```

   Before the fix (random pods):
   ```
   Request:
   Session Pod 1
   Request:
   Session Pod 3
   Request:
   Session Pod 2
   Request:
   Session Pod 1
   ```

   After the fix (sticky to one pod):
   ```
   Request:
   Session Pod 2
   Request:
   Session Pod 2
   Request:
   Session Pod 2
   Request:
   Session Pod 2
   ```

5. **Follow logs in real-time:**
   ```bash
   kubectl logs client -n k8squest -f
   ```

   You should see all responses from the SAME pod. Press Ctrl+C to stop.

Why This Works:
---------------

**sessionAffinity: ClientIP**

Kubernetes uses the client's source IP address to determine which backend pod to route to.

**Process:**
1. Client pod has IP: 10.244.0.5
2. First request: Service picks Pod 2 randomly
3. Service creates mapping: `10.244.0.5 → Pod 2`
4. All future requests from 10.244.0.5 go to Pod 2
5. Mapping persists for `timeoutSeconds` (default: 10800s / 3 hours)

**Hash Function:**
```
hash(client_ip) % num_backends = chosen_backend
```

Same client IP always produces same hash → same backend pod.

Understanding timeoutSeconds:
------------------------------

```yaml
sessionAffinityConfig:
  clientIP:
    timeoutSeconds: 10800  # 3 hours
```

- **Purpose:** How long to maintain the IP-to-pod mapping
- **Default:** 10800 seconds (3 hours)
- **Range:** 1 to 86400 seconds (1 second to 24 hours)
- **Behavior:** After timeout expires, next request may go to a different pod

**Example Timeline:**
```
10:00 AM - User logs in, mapped to Pod 2
10:30 AM - User makes request, goes to Pod 2 ✅
11:00 AM - User makes request, goes to Pod 2 ✅
1:00 PM  - Timeout expires (3 hours later)
1:05 PM  - User makes request, may go to Pod 1 or Pod 3 (new mapping created)
```

Testing Session Affinity:
--------------------------

**Test 1: Verify same-pod routing**
```bash
# Make multiple requests from the same source
kubectl exec client -n k8squest -- sh -c 'for i in 1 2 3 4 5; do wget -q -O- http://session-service; echo; done'
```

All 5 responses should be from the same pod.

**Test 2: Verify different clients get different pods**
```bash
# Create another client pod
kubectl run client2 -n k8squest --image=busybox:1.36 -- sleep 3600

# Make request from client2 (different IP)
kubectl exec client2 -n k8squest -- wget -q -O- http://session-service
```

client2 might get a different pod than client (good for load distribution).

**Test 3: Check service endpoints**
```bash
kubectl get endpoints session-service -n k8squest
```

Should show 3 pod IPs (all 3 backend pods registered).

Common Issues and Fixes:
-------------------------

**Issue 1: Still seeing random pods**
- Wait a few seconds after applying (kube-proxy needs to update iptables)
- Restart client pod to get fresh connection

**Issue 2: Client pod not using affinity**
```bash
# Delete and recreate client pod
kubectl delete pod client -n k8squest
kubectl apply -f broken.yaml
```

**Issue 3: Want to reset affinity**
```bash
# Update the Service (triggers kube-proxy refresh)
kubectl annotate service session-service -n k8squest timestamp="$(date)"
```

When NOT to Use Session Affinity:
----------------------------------

❌ **Don't use if:**
- You can make your app stateless (better solution!)
- You can use shared session storage (Redis, database)
- You need even load distribution
- You want sessions to survive pod restarts

✅ **Use it for:**
- Legacy apps that can't be easily refactored
- Temporary migration strategy
- WebSocket connections (require same pod)
- File uploads (streaming to same pod)

Better Alternatives:
--------------------

Instead of session affinity, consider:

1. **Redis/Memcached for sessions:**
   ```yaml
   # All pods share session storage
   Pod 1 → Redis ← Pod 2
                ↖ Pod 3
   ```

2. **JWT tokens (stateless):**
   ```
   No server-side session needed!
   All state in encrypted token
   ```

3. **Sticky cookies (application layer):**
   ```
   Load balancer sets cookie: pod=pod-2
   All requests include cookie
   ```

Validation:
-----------

Run the validation script:
```bash
./validate.sh
```

You should see: ✅ VALIDATION PASSED!

---
Check solution.yaml to see the complete working configuration.
